# SAM模型整理（[链接](https://segment-anything.com/)）

## 1. 概述

### 1.1 定义和目标
SAM（Segment Anything Model）旨在实现图像分割任务的通用性，使其能够轻松适应不同领域和任务。

### 1.2 应用领域
SAM的主要应用领域包括计算机视觉中的图像分割，广泛应用于科学图像分析、照片编辑等多个领域。

## 2. 工作原理

### 2.1 基本工作原理
SAM通过采用提示性的方法，训练模型以适应多样的数据和任务。其核心工作原理包括对图像进行嵌入，实时将提示信息转换为嵌入向量，并通过轻量级解码器生成分割掩膜。

### 2.2 算法和技术细节
SAM使用零样本学习技术，通过 prompting 技巧预测任何提示的有效分割掩膜。模型的设计简单而实用，能够在 Web 浏览器中实时运行，满足实时交互的需求。

## 3. 遥感应用

### 3.1 具体应用案例
SAM在遥感领域的应用案例涵盖了对不同图像“领域”（例如水下照片或细胞显微镜图像）的直接使用，而无需额外的训练，展现了其零样本迁移的能力。
![2023-10-13-01](https://github.com/ZYJ-Group/Tanghy/assets/94824386/83e34430-a4c9-4480-ac65-45448219fd79)  


### 3.2 结果和效果总结
SAM的通用性使其在许多遥感任务中表现出色，其零样本性能通常与或甚至优于先前的完全监督结果。

# SAV模型整理（[链接](http://sav.cstor.cn/#/)）

## 1. SAV模型与SAM的关系

### 1.1 SAV建立在SAM模型基础之上

Segment Any Video（SAV）是基于 Segment Anything Model（SAM）的一个进一步发展。SAM是图像分割任务的通用性模型，而 SAV 通过引入视频处理和跟踪方法，将 SAM 的能力扩展到视频领域。

### 1.2 创新之处和扩展性

SAV 创新性地解决了 SAM 的一些弱点，包括不能返回语义信息、在某些情况下实例可能被分割为不同部分以及不能处理视频数据的问题。通过整合 YOLOv8 和 SAM，SAV 引入了实例分割和跟踪，使得在视频中能够更准确地分割和追踪对象。

## 2. 算法和设计

### 2.1 SAV模型的基本算法和设计原理

SAV 的核心算法包括两个主要步骤：图像分割和对象追踪。在图像分割阶段，使用 YOLOv8 检测器提供的框作为提示传递给 SAM，以获得语义信息丰富的掩码。在对象追踪阶段，修改了 ultralytics/tracker/track.py 中的代码，将实例分割应用于视频的所有帧。

### 2.2 与SAM的不同之处

SAV 与 SAM 的主要不同之处在于引入了视频处理和跟踪的概念。SAM 主要专注于图像分割，而 SAV 通过整合跟踪机制，使得模型在视频中能够更全面地理解和处理对象。

## 3. 遥感应用

### 3.1 SAV在遥感领域的应用案例

SAV 在遥感领域展现出色的应用，特别是在对不同图像“领域”（例如水下照片或细胞显微镜图像）的直接使用方面。通过视频处理，SAV 能够更好地捕捉和理解遥感图像中的动态变化。
![2023-10-13-03](https://github.com/ZYJ-Group/Tanghy/assets/94824386/27f848fe-4bbd-407d-b08a-03b929db248c)  



### 3.2 与SAM的比较和优势

相比于 SAM，SAV 在遥感应用中的优势主要体现在对动态场景的处理上。SAM 更侧重于静态图像，而 SAV 通过引入视频分割和跟踪，使得在动态环境中更为强大和准确。


