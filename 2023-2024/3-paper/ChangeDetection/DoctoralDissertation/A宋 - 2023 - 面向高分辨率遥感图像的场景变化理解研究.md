# 变化检测-博士毕业论文-绪论-3/13（大方向/篇数）
# 面向高分辨率遥感图像的场景变化理解研究（标题/关键词）
- 宋飞（作者）
- 电子科技大学（学校）
- 链接：paper
- 阅读时间：2023/10/20

### 标题、摘要、关键词、结论
- 标题：面向高分辨率遥感图像的场景变化理解研究
- 摘要：
    随着高分辨率遥感技术的迅速发展，现代遥感图像的品质和数据量得到了巨 大提升。如今，遥感图像具备亚米级空间分辨率、清晰的地物目标几何结构和丰 富的空间细节信息，在地理空间和时间领域的应用中发挥出极高的价值。面向高 分辨率遥感图像的场景变化理解旨在对不同时间同一个区域或目标对象进行反复 观测、识别和分析，达到高分辨遥感图像在时间维度深度理解的最终目标。实际 应用中，对特定场景（如机场）区域进行长期、多时相的反复观测，是分析地物 （飞机）或现象（运动轨迹）随时间变化规律的必要条件。但是，遥感图像场景 变化理解是一项复杂的系统工程，目前仍存在许多未被充分解决或不够完善的关 键技术。
    本文采用计算机视觉技术，根据场景理解的不同层次，从局部区域（或个体） 到全局区域（或整体）的角度出发，研究了高分辨率遥感图像场景变化理解任务 中涉及到的基于对象约束的遥感图像变化检测、遥感目标分析以及遥感场景语义 变化分类三个主要子任务。通过提升这些关键技术，提高对高分辨率遥感图像变 化场景的理解水平。主要的研究内容包括：
    1. 在场景局部区域变化提取方面，提出了基于对象约束的遥感图像变化检测， 可以用于分析不同时间同一个区域的地物变化。受所获取图像本身的特点，场景 的可见性复杂度由多个维度呈现，包括各种场景地物对象的数量、尺度、形状和 位置；以及，遥感系统受光照和地貌结构影响，具有相同语义概念的地物对象在 不同的空间和时间尺度上表现出不同的光谱行为。为了实现了对感兴趣变化对象 的语义约束，本文提出了基于多尺度 Swin Transformer 和深度监督的遥感图像变 化 检 测 方 法 （ Multi-scale Swin Transformer and Depth Supervision Network ， MSTDSNet），其包括三个重要的模块：更宽和更深层次的聚合模块、基于多尺度 Swin Transformer 的度量模块和深度监督模块。在 SYSU-CD 和 LEVIR-CD 公共数 据集上，与五种主流的遥感图像变化检测方法相比，MSTDSNet 达到最高的 F1Score。
    2. 为支持小尺度场景变化理解，本文以遥感图像中的机场为应用场景，提出 了辅助机场变化分析与飞机动向估计的飞机检测技术，即：端对端飞机及其头部 检测器 RAAH-Det（Rotated Aircraft and Aircraft Head Detector）。在遥感图像中， 受各种错综复杂的背景（如建筑物、道路、草地等）和飞机外观差异的影响，难 以准确地建模和提取飞机及其头部的特征。为此，RAAH-Det 开展了三个重要工作：基于 U-ConvNeXt 的感兴趣区域特征提取、具有六个向量的旋转框预测和基 于 循环 Focal Loss 的飞机头部关键点预测。本文将来自 DOTA-v1.5 数据集的 “Plane”类别的旋转框与自标注的飞机头部关键点集成为新数据集 DOTA-Plane。 与七种主流的目标和关键点检测方法相比，RAAH-Det 方法在 DOTA-Plane 数据 集上的评估结果提供了优越的性能。
    3. 为支撑大尺度场景变化理解，从全局（整体）的角度，提出了遥感场景语 义变化分类框架，用于判断两期或多期遥感场景在语义层次所属类别的变化（如： 空置地变成居民区）。在这个过程中，遥感场景分类起到关键的作用，它是实现 场景变化分析的重要技术。最近，大量研究者借助数据驱动和机器学习的算法对 遥感场景分类进行深入研究，提出了许多新的解决思路。然而，现有算法大多数 只关注图像特征表达，目前还是难以处理类内多样性、类间相似性、场景/目标尺 度的大差异性、多类地物目标共存等问题。因此，本文提出了一种基于空间语义 关 系 的 遥 感 场 景 分 类 方 法 （ Local and Gloal Semantic Relationship Network for Remote Sensing Scene Classification，LGSRNet），其包括三个重要的模块：基于 AttConvNeXt 的特征提取，基于图神经网络的语义关系学习模块，基于余弦相似 度的联合表达式学习模块。在两个场景分类数据集（AID 和 NWPU-RESISC45） 上进行的大量实验表明，LGSRNet 优于其它九种主流的方法，能够有效用于对遥 感场景所属类别的变化分析。
    4. 本文建立了面向高分辨率遥感图像的场景变化理解一体化原型系统，并开 展了应用验证实验。根据分析场景区域或地物对象动态变化的速度及过程，将验 证实验划分为长时间间隔（如机场的扩建或新建）和短时间间隔（如机场实时调 度）的两种变化理解。实验结果表明，该系统能够适用于长时间和短时间的机场 场景应用需求，为未来的实际应用奠定了基础。
- 关键词：高分辨遥感图像，场景变化理解，变化检测，目标检测，场景分类

- 目录：
![2023-10-19-18](https://github.com/ZYJ-Group/Tanghy/assets/94824386/a3a4ebf2-63ea-4b7a-974a-90926dd0bdaa)  
![2023-10-19-19](https://github.com/ZYJ-Group/Tanghy/assets/94824386/e8d137f3-5ff5-4495-8e70-cfc88d4e5e42)  

- 索引：  
![2023-10-19-20](https://github.com/ZYJ-Group/Tanghy/assets/94824386/d6421968-92a1-4c5e-be0a-2a053d65aa81)  
![2023-10-19-21](https://github.com/ZYJ-Group/Tanghy/assets/94824386/60510f29-e520-4783-b024-ea99098939b3)  
![2023-10-19-22](https://github.com/ZYJ-Group/Tanghy/assets/94824386/748bae6a-1491-46e5-b254-35b8591ef779)  

# 1.1研究背景与意义

## 概要

近年来，高分辨率遥感图像的广泛应用在生态环境监测、城市规划、军事侦察等领域引起了强烈需求。国内外相继成功发射或生产了一系列高分辨率遥感卫星和轻小型无人机，提供了大量海量遥感数据，标志着遥感观测应用进入大数据时代。研究背景聚焦于高分辨率、大幅面的多时相遥感图像，探讨如何准确地分析和解译其中变化的区域、过程和类型。

## 遥感图像及其分辨率

论文列举了不同分辨率光学成像卫星的技术参数，包括高分、WorldView、QuickBird、GF-1/2/3/4、Landsat7和Landsat8等。这些卫星提供丰富的地物细节信息，使得更加精细的地物种类识别成为可能。

## 场景变化理解

针对高分辨率遥感图像的场景变化理解旨在对不同时间同一个区域进行反复观测、识别和分析，以深度理解观察对象的变化。该领域涉及变化检测、遥感场景目标分析、遥感场景语义变化分类等子任务。

## 子任务与研究方向

- **变化检测：** 通过对不同时间同一区域进行比较，检测场景中的变化，可以是地表覆盖、建筑物、自然环境等的变化。
- **遥感场景目标分析：** 从场景中挖掘感兴趣目标的种类、坐标信息和朝向，辅助场景变化分析。
- **遥感场景语义变化分类：** 利用遥感场景分类方法，将遥感图像分成特定场景类别，实现对语义层面上的变化分析。

## 现有研究与挑战

论文回顾了国内外专家学者在高分辨率遥感图像深度变化理解方面的研究。强调了数据驱动和深度学习在遥感图像处理领域的优势，但也指出仍有挑战，如场景可见性复杂度和光照、地貌结构对解译的影响。

## 本文研究主线

本文以变化检测、遥感场景目标分析和遥感场景语义变化分类为主线，致力于提升高分辨率遥感图像深度变化理解的能力和自动化程度。

### 具体研究工作包括：

1. **变化检测：** 结合深度监督和注意力机制，研究基于对象约束的遥感图像变化检测，提高准确性和实用性。
2. **目标分析：** 研究飞机及其头部视觉属性检测，辅助机场变化分析与飞机动向估计。
3. **场景语义变化分类：** 研究基于空间语义关系的场景分类，采用图神经网络进行关系推理，提高场景分类精度。
![2023-10-19-23](https://github.com/ZYJ-Group/Tanghy/assets/94824386/dc1da9fc-e7a5-4a1d-b433-30992a28636b)  

# 1.2 国内外研究现状及发展趋势

## 概要

高分辨率遥感图像场景变化理解作为多时相遥感图像解译的终极目标，在高分辨率遥感图像处理领域是前沿研究方向之一。该部分聚焦于变化检测、目标分析和场景分类，并探讨了国内外基于计算机视觉技术的研究现状。

## 变化检测

### 问题分析

多时相高分辨率遥感图像的变化检测面临三个具有挑战性的问题：不同成像条件导致光谱行为不同、配准误差、变化对象存在不同尺度大小。

### 研究现状

- **Zhang等[31]:** 使用增量分割方法进行单元分析，通过余弦定律计算变化指数，采用盒须图分析变化对象。
- **Saha等[34]:** 无监督上下文敏感框架深层变化矢量分析，从预训练多层CNN开始获取深层特征。
- **樊玮等[35]:** 提取和融合图像的高级语义特征，构建基于多尺度深度特征融合的变化检测方法。
- **Fu等[36]:** 提出面向高分辨率遥感图像的变化检测方法，包括二元结构分支、全连接层和补丁级别的SoftMax层。
- **Chen等[37]:** 引入时空注意神经网络（STANet），集成自注意模块，解决不同时间和位置的变化检测问题。
- **Chen等[38]:** 提出双时相图像Transformer（BiT），有效地对时空域内的上下文进行建模。

### 挑战和发展趋势

现有方法在解决问题上有一定提升，但仍存在局限性和无法完全解决问题的情况，需要进一步研究新的方法和技术以提高变化检测的精度。

## 1.2.2.面向遥感图像的目标检测

### 通用的目标检测方法
从AlexNet[194]及其在图像分类任务上的革命性性能开始，卷积神经网络（CNN）架构（如VGG[195]、ResNet[198]、EfficientNet[196]和ConvNeXt[160]）通过更大的规模、更广泛的连接和更复杂的卷积形式变得越来越强大。CNN作为各种视觉任务的骨干网络，其性能的进一步提高，极大地促进了目标检测与识别的发展。

早期，双阶段检测器包括R-CNN[43]、Fast R-CNN[44]、Faster R-CNN[45]、Cascade R-CNN[46]。虽然这些基于锚的双阶段检测器已有了不错的检测精度，仍无法满足实际应用对速度的要求。

为了进一步提高运行时效率，以YOLO[47]、SSD[48]为代表的单阶段方法摒弃了双阶段Faster R-CNN的思想，直接通过神经网络同时回归目标的类别概率和位置信息。基于精细设计的轻量级架构，YOLO在VOC2007测试集精度为63.4% mAP，检测速度可以达到45FPS。但是，它只有最后一个特征图可用于预测，这不适合预测多尺度和宽高比的目标对象。为此，SSD采用了在多个特征图上预测对象，且根据每一个特征图对应原图感受野的比例值来预测和回归特定适合尺寸的对象。但是SSD没有限制和筛选容易正确分类的负样本的步骤，导致了前景和背景类别之间不均衡问题，这也是单阶段检测器面临的最主要的问题之一。

### 基于关键点的方法
为了解决上述问题，提出了一系列基于关键点（角点和中心点）的方法。CornerNet、CenterNet、ExtremeNet的性能获得了显著提升。此外，基于Anchor Free的单阶段目标检测算法FCOS和FoveaBox的精度提高了不少，但也让单阶段检测算法的速度与RetinaNet相比变慢了。

最近，ViT的创新性工作直接采用了一系列不重叠的固定尺寸图像补丁上的Transformer来进行图像分类、目标检测等任务。与CNN相比，ViT在图像分类中成功地实现了运行速度和检测精度之间的协调。然而，普通ViT在常见的图像分类、目标检测、场景理解和语义分割等计算机视觉任务中仍存在一些困难。
Faster R-CNN相关系列着重于专注精度，而YOLO系列注重速度。未来的发展方向更加注重平衡精度和速度，这也是很多模型在SSD系列上探索的方向。目标选框从Region Based和Anchor Based到基于角点，CornerNet是一个开拓思路的方向，未来的目标选框方法依旧是研究的一个重要方向。零样本、“Any-Shot检测”可以有效减少数据标注的依赖，具有重要的应用前景和潜在的经济价值和社会价值。

### 面向遥感图像的目标检测方法

在自然场景图像中，通常采用水平框（Horizontal Bounding Boxes，HBB）来描述物体的位置。然而，由于遥感系统特殊的自顶向下拍摄的独特视角，光学遥感图像中所有感兴趣的物体都位于不同的方向上。为此，出现了各种优越的旋转目标检测器，采用旋转框（Orientated Bounding Boxes，OBB）来更准确地检测遥感图像中的目标。

目前的旋转目标检测器通常是水平目标检测器的延伸，例如，基于区域候选网络（Region Proposal Network，RPN）和ROI-pooled特征的旋转区域CNN（Rotational Region CNN，R2CNN）[166]来产生旋转和水平框。同时，设计了两种不同形式的旋转区域候选网络（Rotation Region Proposal Networks，RRPN）[167]和（Rotated Region Proposal Networks，R2PN）[170]，以获得具有倾斜角度候选框。

Zhang等[70]改进后的卷积神经网络，实现了不同尺度、旋转目标的检测。RoI Transformer[150]在RoI上采用空间变换来保持旋转不变性。ICN[171]将图像级联和特征金字塔网络相结合，提取强和弱语义的多尺度特征图。结果表明，在DOTA数据集上获得了令人满意的性能。但是，所有这些方法都涉及到生成大量的锚定框（Anchor）。同时，对目标边界框与锚定框之间的位置偏移量进行回归，以优化预测框的位置。这里，基于锚的策略受到负和正锚框不平衡问题的影响，导致训练速度慢，检测性能次优。关键特征捕获网络（Critical Feature Capturing Network，CFC-Net）[187]是一个单阶段检测器，每个位置只对应一个锚定框，相当于推理速度较高的无锚定框方法。

在遥感目标检测任务中，由于受遥感图像分辨率自身的影响，会导致大多数目标在场景中占比小，即小目标。目前，小目标检测有两种定义方式：根据相对尺寸的定义和根据绝对尺寸的定义。根据国际组织SPIE的定义，在256 × 256的图像中目标面积小于80个像素可以称为小目标，即小目标仅仅占256 × 256图像的0.12%的像素个数，此为相对尺寸的定义。另外一种定义目标尺寸大小的方法是绝对尺寸的定义。根据MS COCO数据集的定义，尺寸小于等于32 × 32像素的目标被当作是小目标，该尺寸阈值仅适用于自然场景下的目标。

尽管许多目标检测算法在检测大中型目标有不错的性能，但在小目标的检测上性能仍然不尽人意。这是因为小目标检测存在三个难点：
1. 小目标的分辨率低，图像相对模糊，携带的信息较少，难以提取可靠的特征，很难区分出前景与背景、类别与类别之间相似度高的目标（误检）；
2. 小目标检测对位置的精度要求更高，两三个像素的偏差就可能导致漏检；
3. 在一些场景中，小目标分部比较密集，会导致漏检或错检。


目前，小目标检测的方法主要通过增加输入图像分辨率[71-74]或通过将高分辨率特征与来自低分辨率图像的高维特征融合[75-77]来解决。关于前者，超分辨率GAN（Super-Resolution Generative Adversarial Network，SRGAN）[71]和增强型超分辨率GAN（Enhanced Super-Resolution Generative Adversarial Network，ESRGAN）[72]在增强有无噪声的低分辨率图像方面表现出卓越的性能。
## 1.2.3.面向遥感图像的场景分类

影响场景分类性能的存在两方面问题：

### 1. 长尾分布问题
长尾分布是现实世界的一大难题，指的是少部分类别占据了大量样本，而大部分类别却只有少数样本。解决这一问题最主流的方法是类别再平衡策略，即通过重采样或代价敏感重加权来缓解类别不平衡问题。

### 2. 特征表达问题
目前，影响遥感场景分类的特征表达的因素主要包括：
- 类内多样性
- 类间相似性
- 场景/目标尺度的大差异性
- 多类地物目标共存

针对长尾问题，目前主要的方法是 Re-balancing，分为 Re-sampling 和 Re-weighting 两类。Re-sampling 通过重采样的方法使训练集和测试集尽量维持一致的分布，包括 Over-sampling 和 Under-sampling。Re-weighting 是直接在损失函数上对 Loss 进行加权，给 Tail 类赋予更大的权重，提升 Tail 类的性能。
对于 Re-balancing 方法，2019 年的两篇 SOTA 是 CB-Focal 和 LDAM。CB-Focal 提出了有效样本的概念，并通过有效样本的数量对不同类别的损失进行重加权。LDAM 赋予了不同类别不同的 Margin，同时采取了一种特殊的两阶段的 Re-weighting 策略，在长尾数据集上取得了 SOTA 的效果。

### 遥感图像场景分类方法

遥感图像场景分类可根据特征类型分为基于人工设计特征和基于深度特征的方法。

#### 人工设计特征
通常情况下，人工设计特征是由研究者根据场景地貌特点和分类要求，通过精细设计并明确提取的低层密集特征。然而，这些特征通常包含大量冗余信息，导致分类准确度较差。因此，特征选择方法被广泛应用于改进这些特征，提高其稀疏性和对旋转、尺度等变化的不变性，以提高分类性能。

光谱特征通常包括灰度值、图像灰度值均值和方差。图像灰度值被直接运用当作一种分类特征，而图像灰度值的均值和方差也被应用于进行分类。相比之下，高层特征是指利用深度学习提取的特征。

#### 深度学习特征
近年来，大量研究者将目光转向基于深度学习的遥感图像场景分类方法，通过深度神经网络自动学习图像特征，实现更为准确和高效的分类。

一些方法包括：
- 利用判别相关性分析方法（DCA）融合 VGGNet 的两个全连接层的特征。
- 采用特征袋融合 CNN 卷积层特征的方式。
- 提出一种新的特征融合方法，整合了不同模型的输出特征。
- 分别选取 VGG 和 ResNet 进行全局特征的生成。
- 设计了双模型架构（BBN）可以同时处理表征学习和分类器学习。

最近，基于 CNN 和循环神经网络的模型利用局部和全局空间关系信息来增强学习特征表达能力。

# 1.3 主要研究内容与关键技术

高分辨率遥感图像能够提供丰富的地物细节信息与分布模式信息，能够实时精确地挖掘更精细的地表变化信息，为更好地指导在民用和军事等领域的科学决策起着非常重要的作用。在中国大多数城市经历了广泛的土地利用和土地覆盖变化的背景下，本文聚焦于发展中的城市进行场景变化理解，以帮助决策者应对城市可持续发展。同时，根据课题组项目需求，针对机场场景开展应用研究和验证。

接下来，本章将对本文主要研究内容和关键技术进行简要的介绍，根据场景地物的构建层次，从局部区域（或个体）到全局区域（或整体）的角度出发，具体的研究工作如下：

### 1. 基于对象约束的遥感图像变化检测研究

在大幅面高分辨率遥感图像场景理解任务中，由于背景信息复杂化的影响，有用信息的准确提取受到很大干扰。因此，本文提出了一种有效的基于对象约束的遥感图像变化检测方法，以分割线性目标和复杂结构目标的变化地物为处理单元，并抑制传统方法难以应对的挑战，提高变化信息的可分性。

### 2. 辅助机场变化分析与飞机动向估计的飞机检测

除了准确检测感兴趣目标的位置信息外，预测目标的其它视觉属性信息也非常重要。本文探索感兴趣目标和视觉属性之间的全局和局部特征关系，以期望将飞机检测网络和属性预测网络统一成一个端对端的整体，辅助机场变化分析与飞机动向估计。

### 3. 遥感场景语义变化分类研究

遥感场景语义变化分类是一项重要的高分辨率图像场景变化理解任务。本文提出了一种挖掘空间语义关系的遥感场景分类方法，通过充分利用遥感图像的地物空间关系，结合深度学习的优势特性，进一步提高分类精度和鲁棒性，从而有效地应用于遥感场景所属类别的变化分析。

### 4. 遥感场景变化理解的应用及实验验证

结合上述三种核心方法，本文构建了一体化的原型系统，旨在完成高分辨率遥感图像场景变化理解任务。该系统内的模块均为相互独立的，提供各自专属的精度评估指标，可以通过算法工作流方式按需组合，以满足用户的特殊需求，实现多方面的处理和分析。


# 总结

## 主要内容

这篇文章深入探讨了高分辨率图像变化检测的关键问题，主要分为以下几个方面的研究内容：

### 1. 基于对象约束的遥感图像变化检测研究

在这一部分，文章提出了一种有效的基于对象约束的遥感图像变化检测方法。该方法的关键在于分割线性目标和复杂结构目标的变化地物，同时抑制了背景信息复杂化带来的干扰，提高了变化信息的可分性。

### 2. 辅助机场变化分析与飞机动向估计的飞机检测

在这一研究方向，文章探索了感兴趣目标和视觉属性之间的全局和局部特征关系。目标是将飞机检测网络和属性预测网络统一成一个端对端的整体，以实现辅助机场变化分析与飞机动向估计。

### 3. 遥感场景语义变化分类研究

遥感场景语义变化分类是本文的另一关键研究方向。文章提出了一种挖掘空间语义关系的遥感场景分类方法，充分利用遥感图像的地物空间关系，结合深度学习，提高分类精度和鲁棒性，应用于遥感场景所属类别的变化分析。

### 4. 遥感场景变化理解的应用及实验验证

最后，文章将上述研究内容整合，构建了一体化的原型系统。该系统模块独立且灵活，提供各自专属的精度评估指标。通过算法工作流方式按需组合，实现多方面的处理和分析。

