# 论文复现-1/10（大方向/篇数）
# Remote Sensing Image Change Detection with Transformers（标题/关键词）
- Hao Chen（作者）
- IEEE Transactions on Geoscience and Remote Sensing
- 链接：paper
- 阅读时间：2023/10/25

## 简介
    摘要：现代变化检测（CD）凭借深度卷积强大的判别能力取得了显着的成功。然而，由于场景中物体的复杂性，高分辨率遥感 CD 仍然具有挑战性。具有相同语义概念的物体在不同时间和空间位置可能表现出不同的光谱特征。最近使用纯卷积的 CD 管道仍在努力将时空中的远程概念联系起来。非局部自注意力方法通过对像素之间的密集关系进行建模而显示出良好的性能，但计算效率较低。在这里，我们提出了一种双时态图像转换器（BIT）来高效且有效地对时空域内的上下文进行建模。我们的直觉是，兴趣变化的高级概念可以用一些视觉单词（即语义标记）来表示。为了实现这一目标，我们将双时图像表达为几个标记，并使用变换器编码器来对基于紧凑标记的时空中的上下文进行建模。然后，将学习到的上下文丰富的标记反馈到像素空间，以通过转换器解码器细化原始特征。我们将 BIT 纳入基于深度特征差异的 CD 框架中。对三个 CD 数据集的广泛实验证明了所提出方法的有效性和效率。值得注意的是，我们基于 BIT 的模型显着优于纯卷积基线，计算成本和模型参数仅降低了 3 倍。基于没有复杂结构（例如 FPN、UNet）的朴素主干网（ResNet18），我们的模型超越了几种最先进的 CD 方法，包括在效率和准确性方面优于最近四种基于注意力的方法。我们的代码可在 https://github.com/justchenhao/BIT CD 获取。

## 关键词
    变化检测（CD）、高分辨率光学遥感（RS）图像、变压器、注意力机制、卷积神经网络（CNN）。

## 一、介绍
    变化检测（CD）是遥感（RS）领域的主要课题之一。 CD 的目标是通过比较在不同时间拍摄的同一区域的共同配准图像，为区域中的每个像素分配二进制标签（即变化或不变化）[1]。变化的定义因应用而异，例如城市扩张[2]、森林砍伐[3]和损害评估[4]。基于遥感图像的信息提取仍然主要依靠人工目视判读。自动CD技术可以减少大量的劳动力成本和时间消耗，因而引起越来越多的关注[2, 513]。高分辨率 (HR) 卫星数据和航空数据的可用性为精细监测土地覆盖和土地利用开辟了新途径。基于 HR 光学 RS 图像的 CD 在两个方面仍然是一项具有挑战性的任务：1）场景中存在的物体的复杂性，2）不同的成像条件。两者都有助于具有相同语义概念的对象在不同时间和不同空间位置（时空）表现出不同的光谱特征。例如，如图1（a）所示，场景中的建筑物对象具有不同的形状和外观（黄色框中），并且同一建筑物对象在不同时间可能由于光照而具有不同的颜色（红色框中）变化和外观改变。为了识别复杂场景中的兴趣变化，强大的CD模型需要：1）识别场景中兴趣变化的高级语义信息，2）区分真实变化和复杂的不相关变化。如今，由于其强大的判别能力，深度卷积神经网络（CNN）已成功应用于RS图像分析，并在CD任务中表现出良好的性能[5]。最近的监督 CD 方法 [2, 6-13] 依赖于基于 CNN 的结构从每个时间图像中提取揭示兴趣变化的高级语义特征。由于空间和时间范围内的上下文建模对于识别高分辨率遥感图像的兴趣变化至关重要，因此最新的努力一直集中在通过堆叠更多卷积层来增加模型的接收场（RF）[2, 6 –8]，使用扩张卷积 [7]，并应用注意力机制 [2,6,9–13]。与本质上受限于 RF 大小的纯粹基于卷积的方法不同，基于注意力的方法（通道注意力 [9–12]、空间注意力 [9–11] 和自注意力 [2, 6, 13]）在建模全局信息方面是有效的。然而，大多数现有方法仍然在努力将时空中的远程概念联系起来，因为它们要么分别对每个时间图像应用注意力以增强其特征[9]，要么简单地使用注意力来重新加权融合的双时特征/通道或空间维度中的图像[10–12, 14]。最近的一些工作 [2,6,13] 通过利用自注意力对时空中任何像素对之间的语义关系进行建模，取得了有希望的性能。然而，它们的计算效率低下，并且需要高计算复杂度，并且计算复杂度随着像素数量呈二次方增长。为了应对上述挑战，在这项工作中，我们引入了双时态图像变换器（BIT），以高效且有效的方式对双时态图像中的远程上下文进行建模。我们的直觉是，兴趣变化的高级概念可以用一些视觉单词（即语义标记）来表示。我们的 BIT 不是对像素空间中像素之间的密集关系进行建模，而是将输入图像表达为一些高级语义标记，并在基于紧凑标记的时空中对上下文进行建模。此外，我们通过利用每个像素和语义标记之间的关系来增强原始像素空间的特征表示。图 1 给出了一个例子来展示我们的 BIT 对图像特征的影响。考虑到与建筑概念相关的原始图像特征（见图 1 (b)），我们的 BIT 学习通过考虑时空的全局背景来进一步一致地突出显示建筑区域（见图 1 (c)）。请注意，我们显示了增强特征和原始特征之间的差异图像，以更好地展示所提出的 BIT 的作用。我们将 BIT 纳入基于深度特征差异的 CD 框架中。我们基于 BIT 的模型的整体过程如图 2 所示。CNN 主干网 (ResNet) 用于从输入图像对中提取高级语义特征。我们利用空间注意力将每个时间特征图转换为一组紧凑的语义标记。然后我们使用 Transformer [15] 编码器对两个标记集中的上下文进行建模。由此产生的上下文丰富的标记由连体变换器解码器重新投影到像素空间，以增强原始像素级特征。最后，我们根据两个细化的特征图计算特征差异图像（FDI），然后将它们输入浅层 CNN 以产生像素级变化预测。我们的工作贡献可以概括如下： • 提出了一种有效的基于变压器的遥感图像变化检测方法。我们将 Transformer 引入到 CD 任务中，以更好地对双时图像内的上下文进行建模，这有利于识别感兴趣的变化并排除不相关的变化。 • 我们的 BIT 不是对像素空间中任何元素对之间的密集关系进行建模，而是将输入图像表达为几个视觉单词（即标记），并在基于紧凑标记的时空中对上下文进行建模。 • 对三个CD 数据集的广泛实验验证了所提出方法的有效性和效率。我们用 BIT 替换 ResNet18 的最后一个卷积阶段，所得到的基于 BIT 的模型的性能优于纯卷积模型，且计算成本和模型参数仅降低了 3 倍。基于没有复杂结构（例如 FPN、UNet）的朴素 CNN 主干，我们的方法在效率和准确性方面表现出比最近几种基于注意力的 CD 方法更好的性能。本文的其余部分安排如下。第二部分描述了基于深度学习的 CD 方法的相关工作以及 RS 中最近基于 Transformer 的模型。第三节详细介绍了我们提出的方法。第四节报告了一些实验结果。第五节进行讨论，第六节得出结论。

## 六、总结
    在本文中，我们提出了一种有效的基于变压器的遥感图像变化检测模型。我们的 BIT 学习一组紧凑的标记来表示高级概念，这些概念揭示了双时态图像中存在的兴趣变化。我们利用转换器来关联基于令牌的时空中的语义概念。大量的实验验证了我们方法的有效性。我们用 BIT 取代 ResNet18 的最后一个卷积阶段，获​​得了显着的精度提升（LEVIR-CD/WHU-CD/DSIFN-CD 测试集上的 F1 分数为 1.7/2.4/10.8 分），计算复杂度降低了 3 倍，模型参数小 3 倍。我们的经验证据表明 BIT 比纯卷积模块更高效、更有效。仅使用简单的 CNN 主干 (ResNet18)，我们的方法优于其他几种采用更复杂结构的 CD 方法，例如 FPN 和 UNet。我们还在三个 CD 数据集上展示了比最近四种基于注意力的方法在效率和准确性方面更好的性能。

## 二、相关工作
### A 基于深度学习的遥感图像变化检测
    基于深度学习的光学遥感图像监督CD方法通常可以分为两个主流[8]。一种是两阶段解决方案[16-18]，其中训练CNN/FCN对双时图像进行单独分类，然后比较它们的分类结果以做出改变决策。这种方法仅当变化标签和双时态语义标签都可用时才实用。另一种是单阶段解决方案，它直接从双时态图像产生变化结果。补丁级方法 [19-21] 将 CD 任务建模为相似性检测过程，将双时图像分组为补丁对，并在每对上使用 CNN 以获得其中心预测。像素级方法 [2, 3, 6, 7, 9–13, 2228] 使用 FCN 直接从两个输入生成高分辨率变化图，这通常比块级方法更高效和有效。由于CD任务需要处理两个输入，因此如何融合双时态信息是一个重要的课题。现有的基于FCN的方法可以根据双时信息融合的阶段大致分为两类。图像级方法 [3, 22–24, 29] 将双时图像连接起来作为语义分割网络的单个输入。特征级方法[2,6,7,9-12,22,25-28,30]结合了从神经网络中提取的双时态特征，并根据融合特征做出变更决策。最近的许多工作旨在通过设计多级特征融合结构[2,9,10,12,26,30]，结合基于GAN的优化目标[23,26,28, 31]，并增加模型的接收场（RF），以便在空间和时间范围方面更好地进行上下文建模[2, 6-13]。由于场景中物体的复杂性和图像条件的变化，上下文建模对于识别高分辨率遥感图像的兴趣变化至关重要。为了增加 RF 大小，现有方法包括采用更深的 CNN 模型 [2, 6–8]、使用扩张卷积 [7] 以及应用注意力机制 [2, 6, 9–13]。例如，张等人。 [7]应用深度CNN主干（ResNet101[32]）来提取图像特征并使用扩张卷积来扩大模型的RF尺寸。考虑到纯卷积网络本质上受限于每个像素的 RF 大小，许多最新的工作都集中在引入注意力机制来进一步扩大模型的 RF，例如通道注意力 [912]、空间注意力 [9-11] ]，自注意力[2,6,13]。然而，他们中的大多数人仍然在努力充分利用与时间相关的上下文，因为他们要么将注意力视为每个时态图像单独的特征增强模块[9]，要么简单地使用注意力来重新加权融合的双时态特征/图像在通道或空间维度上[10-12]。非局部自注意力 [2, 6] 由于其能够利用时空像素之间的全局关系而表现出有希望的性能。然而，它们的计算效率低下，并且需要高计算复杂度，并且计算复杂度随着像素数量呈二次方增长。我们论文的主要目的是以高效且有效的方式学习和利用双时图像中的全局语义信息，以提高 CD 性能。与现有的基于注意力的 CD 方法直接对基于像素的空间中任意元素对之间的密集关系进行建模不同，我们从图像中提取一些语义标记并在基于标记的时空中对上下文进行建模。然后利用生成的上下文丰富的标记来增强像素空间中的原始特征。我们的直觉是，场景内兴趣的变化可以通过一些视觉单词（标记）来描述，并且每个像素的高级特征可以通过这些语义标记的组合来表示。因此，我们的方法表现出高效率和高性能。

### B 基于 Transformer 的模型 Transformer
    Transformer 于 2017 年首次推出[15]，已广泛应用于自然语言处理（NLP）领域，以解决序列到序列的任务，同时轻松处理长距离 4 依赖关系。最近的趋势是在计算机视觉（CV）领域采用 Transformer。由于 Transformer 强大的表示能力，基于 Transformer 的模型在各种视觉任务中表现出与卷积模型相当甚至更好的性能，包括图像分类 [33–35]、分割 [35–37]、对象检测 [36, 38, 39]、图像生成 [40, 41]、图像字幕 [42] 和超分辨率 [43, 44]。 Transformer 模型在 NLP/CV 任务上的惊人性能引起了遥感界研究其在遥感任务中的应用的兴趣，例如图像时间序列分类 [45, 46]、高光谱图像分类 [47]、场景分类 [48] ]，以及遥感图像字幕 [49, 50]。例如，李等人。 [46]提出了一种 CNN 变换器方法来执行时间序列图像的作物分类，其中变换器用于从通过 CNN 提取的多时相特征序列中学习与土地覆盖语义相关的模式。他等人。 [47]应用了变压器的变体（BERT [51]）来捕获高光谱图像分类中像素之间的全局依赖性。此外，王等人。 [50]利用变压器将CNN从给定的RS图像中提取的无序单词翻译成结构良好的句子。在本文中，我们探讨了 Transformer 在二进制 CD 任务中的潜力。我们提出的基于 BIT 的方法在建模时空中的全局语义关系方面是高效且有效的，有利于兴趣变化的特征表示。

## 三、基于高效 Transformer 的变化检测模型
    我们基于 BIT 的模型的整体过程如图 2 所示。我们将 BIT 合并到正常的变化检测管道中，因为我们希望利用卷积和 Transformer 的优势。我们的模型从几个卷积块开始，以获得每个输入图像的特征图，然后将它们输入 BIT 以生成增强的双时特征。最后，将生成的特征图馈送到预测头以产生像素级预测。我们的主要见解是，BIT 学习并关联高级语义概念的全局上下文，以及反馈以有益于原始的双时态特征。我们的 BIT 具有三个主要组件：1）暹罗语义标记器，它将像素分组为概念，为每个时间输入生成一组紧凑的语义标记；2）变换器编码器，它在基于标记的空间中对语义概念的上下文进行建模 -时间，以及3）连体变换器解码器，它将相应的语义标记投影回像素空间以获得每个时间的细化特征图。我们基于 BIT 的变化检测模型的推理细节如算法 1 所示。

### A 语义标记器
    我们的直觉是，输入图像的兴趣变化可以通过一些高级概念（即语义标记）来描述。并且语义概念可以共享通过双时态图像。为此，我们采用 Siamese tokenizer 从每个时间的特征图中提取紧凑的语义标记。类似于 NLP 中的分词器，它将输入句子分割成几个元素（即单词或短语），并用一个词向量表示每个元素，我们的语义分词器将整个图像分割成几个视觉单词，每个词对应一个词向量。如图 3 所示，为了获得紧凑的标记，我们的标记器学习一组空间注意图，以将特征图在空间上池化为一组特征，即标记集。令 X1, X2 ∈ RHW ×C 为输入双时特征图，其中 H、W、C 为特征图的高度、宽度和通道维度。令 T1、T2 ∈ RL×C 为两组标记，其中 L 为标记词汇集的大小。对于特征图 Xi(i = 1, 2) 上的每个像素 Xip，我们使用逐点卷积获得 L 个语义组，每个组表示一个语义概念。然后，我们通过在每个语义组的 HW 维度上运行的 softmax 函数来计算空间注意力图。最后，我们使用注意力图来计算像素的加权平均和Xi 中获得大小为 L 的紧凑词汇集，即语义标记 Ti。形式上，Ti = (Ai)T Xi = (σ(φ(Xi; W)))T Xi, (1) 其中 φ(·) 表示具有可学习核 W ∈ RC×L 的逐点卷积，σ( ·) 是 softmax 函数，用于对每个语义组进行归一化以获得注意力图 Ai ∈ RHW ×L。 Ti 由 Ai 和 Xi 相乘计算得出。

### B Transformer Encoder
    在获得输入双时图像的两个语义标记集 T1、T2 后，我们使用变压器编码器对这些标记之间的上下文进行建模[15]。我们的动机是，基于标记的时空中的全局语义关系可以被转换器充分利用，从而为每个时间生成上下文丰富的标记表示。如图4（a）所示，我们首先将两组令牌连接成一个令牌集合T ∈ R2L×C ，并将其输入到变压器编码器中以获得新的令牌集合Tnew。最后，我们将标记分成两组 Tinew(i = 1, 2)。 Transformer 编码器由 NE 层多头自注意力（MSA）和多层感知器（MLP）块组成（图 4（a））。与使用后范数残差单元的原始变压器不同，我们遵循ViT[33]采用前范数残差单元（PreNorm），即层归一化发生在MSA/MLP之前。 PreNorm 已被证明比对应的版本更稳定、更有能力 [52]。在每一层 l，自注意力的输入是一个三元组（查询 Q、键 K、值 V），根据输入 T(l−1) ∈ R2L×C 计算得出：Q = T(l−1)Wq， K = T(l−1)Wk, V = T(l−1)Wv, (2) 其中 Wl−1 q , Wl−1 k , Wl−1 v ∈ RC×d 是三个线性投影的可学习参数层数，d 是三元组的通道维度。一个注意力头的公式为： Att(Q, K, V) = σ ( QKT √d ) V, (3) 其中 σ(·) 表示在通道维度上运行的 softmax 函数。 Transformer编码器的核心思想是多头自注意力。 MSA 并行执行多个独立的注意力头，并将输出连接起来，然后投影以产生最终值。 MSA的优点是它可以共同关注来自不同位置的不同表示子空间的信息。形式上，MSA(T(l−1)) = Concat(head1, .., headh)WO，其中 headj = Att(T(l−1)Wq j , T(l−1)Wk j , T(l−1) 1)Wv j ), (4) 其中Wq j , Wk j , Wv j ∈ RC×d, WO ∈ Rhd×C 是线性投影矩阵，h 是注意力头的数量。 MLP 块由两个线性变换层组成，中间有一个 GELU [53] 激活。输入和输出的维度为C，内层的维度为2C。形式上，MLP(T(l−1)) = GELU(T(l−1)W1)W2 (5) 其中 W1 ∈ RC×2C ，W2 ∈ R2C×C 是线性投影矩阵。请注意，我们将可学习位置嵌入（PE）WP E ∈ R2L×C 添加到令牌序列 T，然后将其馈送到转换器层。我们的经验证据（第 IV-D 节）表明有必要对代币补充 PE。 PE 对基于令牌的时空中元素的相对或绝对位置的信息进行编码。这样的位置信息可以有利于上下文建模。例如，时间位置信息可以指导转换器利用时间相关的上下文。

### C Transformer Decoder
    到目前为止，我们已经为每个时间图像获得了两组上下文丰富的标记 Tinew(i = 1, 2)。这些上下文丰富的标记包含紧凑的高级语义信息，可以很好地揭示兴趣的变化。现在，我们需要将概念的表示投影回像素空间以获得像素级特征。为了实现这一点，我们使用改进的 Siamese Transformer 解码器 [15] 来细化每个时间的图像特征。如图4（b）所示，给定特征序列Xi，变压器解码器利用每个像素和标记集Tinew之间的关系来获得细化特征Xinew。我们将 Xi 中的像素视为查询，将标记视为键​​。我们的直觉是每个像素都可以由紧凑语义标记的组合来表示。我们的 Transformer 解码器由多头交叉注意 (MA) 和 MLP 块的 ND 层组成。与[15]中的原始实现不同，我们删除了MSA块以避免Xi中像素6之间密集关系的大量计算。我们采用 PerNorm 和与 MLP 相同的配置作为 Transformer 编码器。在MSA中，查询、键和值来自相同的输入序列，而在MA中，查询来自图像特征Xi，键和值来自标记Tinew。形式上，在每一层 l，MA 定义为： MA(Xi,(l−1), Ti new) = Concat(head1, ..., headh)WO，其中 headj = Att(Xi,(l−1) Wq j , Ti new Wk j , Ti new Wv j ), (6) 其中 Wq j , Wk j , Wv j ∈ RC×d, WO ∈ Rhd×C 是线性投影矩阵，h 是注意力头的数量。请注意，我们不会将 PE 添加到输入查询中，因为我们的经验证据（第 IV-D 节）显示添加 PE 时没有显着的收益。

### D Network Details
    CNN骨干。我们使用修改后的 ResNet18 [32] 来提取双时图像特征图。原始ResNet18有5个阶段，每个阶段下采样2。我们将最后两个阶段的步长替换为1，并在ResNet后面添加逐点卷积（输出通道C = 32）以减少特征维度，然后是双线性插值层，从而获得下采样因子为4的输出特征图，以减少空间细节的损失。我们将此主干命名为 ResNet18 S5。为了验证所提出方法的有效性，我们还使用了两个更轻的主干，即ResNet18 S4/ResNet18 S3，其仅使用ResNet18的前四个/三个阶段。  
    双时图像转换器。根据第 2 节中的参数实验。 IV-E，我们设置 token 长度 L = 4。我们将 Transformer 编码器的层数设置为 1，Transformer 解码器的层数设置为 8。MSA 和 MA 中的头数 h 设置为 8，通道维度设置为 d每个头设置为8。  
    预测头。受益于 CNN 主干和 BIT 提取的高级语义特征，采用非常浅的 FCN 进行变化判别。给定 BIT 输出的两个上采样特征图 X1*、X2* ∈ RH0×W0×C（H0、W0 分别是原始图像的高度、宽度），预测头将生成预测变化概率图 P ε RH0×W0×2，由下式给出： P = σ(g(D)) = σ(g(|X1* − X2*|)), (7) 其中特征差异图像 (FDI) D ε RH0×W0 ×C 是两个特征图相减的逐元素绝对值，g : RH0×W0×C → RH0×W0×2 是变化分类器，σ(·) 表示在通道上逐像素操作的 softmax 函数分类器输出的维度。我们的变化分类器的配置是两个带有 BatchNorm 的 3×3 卷积层。每个卷积的输出通道为“32, 2”。在推理阶段，预测掩码 M ∈ RH0×W0 通过对 P 的通道维度进行像素级 Argmax 运算来计算。  
    损失函数。在训练阶段，我们最小化交叉熵损失来优化网络参数。形式上，损失函数定义为： L= 1 H0 × W0 H,W Σ h=1,w=1 l(Phw, Yhw), (8) 其中 l(Phw, y) = −log(Phwy) 为交叉熵损失，Yhw 是位置 (h, w) 处像素的标签。

## 四、实验结果与分析
### A 实验设置
    我们对三个变化检测数据集进行了实验。   
    LEVIR-CD [2] 是一个公共的大型建筑 CD 数据集。它包含 637 对尺寸为 1024 × 1024 的高分辨率 (0.5m) RS 图像。我们遵循其默认数据集分割（训练/验证/测试）。由于GPU内存容量的限制，我们将图像切割成大小为256×256的小块，没有重叠。因此，我们分别获得了 7120/1024/2048 对用于训练/验证/测试的补丁。   
    WHU-CD [54] 是一个公共建筑 CD 数据集。它包含一对尺寸为 32507 × 15354 的高分辨率（0.075m）航拍图像。由于[54]中没有提供数据分割解决方案，我们将图像裁剪成尺寸为 256 × 256 的小块，没有重叠并随机分割它分为三部分：6096/762/762分别用于训练/验证/测试。   
    DSIFN-CD [10] 是一个公共二进制 CD 数据集。它包括分别来自中国六个主要城市的六对大型高分辨率（2m）卫星图像。该数据集包含道路、建筑物、农田、水体等多种土地覆盖对象的变化。我们遵循作者提供的大小为 512 × 512 的默认裁剪样本。我们分别有 3600/340/48 个样本用于训练/验证/测试。  
    为了验证我们基于BIT的模型的有效性，我们设置了以下模型进行比较：   
    • Base：我们的基线模型，由CNN主干（ResNet18 S5）和预测头组成。   
    • BIT：我们基于BIT 的轻量主干模型(ResNet18 S4)。  
    为了进一步评估所提出方法的效率，我们另外设置了以下模型：   
    • Base S4：轻CNN主干（ResNet18 S4）+预测头。   
    • Base S3：一个轻量级CNN主干（ResNet18 S3）+预测头。   
    • BIT S3：我们基于BIT 的模型，具有更轻的骨干网(ResNet18 S3)。  
    实施细节。我们的模型在 PyTorch 上实现，并使用单个 NVIDIA Tesla V100 GPU 进行训练。我们将正常的数据增强应用于输入图像块，包括翻转、重新缩放、裁剪和高斯模糊。我们使用带有动量的随机梯度下降（SGD）来优化模型。我们将动量设置为 0.99，权重衰减设置为 0.0005。学习率最初设置为 0.01，并线性衰减到 0，直到训练 200 个 epoch。已执行验证在每个训练周期之后，验证集上的最佳模型用于测试集上的评估。  
    评估指标。我们使用变化类别的F1分数作为主要评价指标。 F1-score 由测试的精确率和召回率计算得出，如下： F1 = 2 召回率−1 + 精度−1 , (9) 另外，变化类别的精度、召回率、并交集 (IoU) 以及总体准确率(OA) 也有报道。上述指标定义如下： 精度 = TP / (TP + FP) 召回率 = TP / (TP+FN) IoU = TP / (TP+FN+FP) OA = (TP+TN) / (TP+TN+ FN+FP) (10) 其中TP、FP、FN分别表示真阳性、假阳性、假阴性的数量。

### B 与最先进技术的比较
    我们与几种最先进的方法进行了比较，包括三种纯粹基于卷积的方法（FCEF [22]、FC-Siam-Di [22]、FC-Siam-Conc [22]）和四种注意力机制基于方法（DTCDSCN [9]、STANet [2]、IFNet [10] 和 SNUNet [14]）。   
    • FC-EF [22]：图像级融合方法，其中双时态图像作为单个输入连接到全卷积网络。   
    • FC-Siam-Di [22]：特征级融合方法，采用Siamese FCN提取多级特征，并利用特征差异来融合双时态信息。   
    • FC-Siam-Conc [22]：特征级融合方法，采用 Siamese FCN 提取多级特征，并使用特征级联来融合双时态信息。   
    • DTCDSCN [9]：多尺度特征级联方法，将通道注意力和空间注意力添加到深层Siamese FCN中，从而获得更具判别性的特征。请注意，他们还在每个时间的标签图的监督下训练了两个额外的语义分割解码器。为了公平比较，我们省略了语义分割解码器。   
    • STANet [2]：基于Metric-based Siamese FCN 的方法，它集成了时空注意力机制以获得更多判别性特征。   
    • IFNet [10]：多尺度特征串联方法，将通道注意力和空间注意力应用于解码器每一级的串联双时特征。深度监督（即计算解码器每个级别的监督损失）用于更好地训练中间层。   
    • SNUNet [14]：多尺度特征级联方法，结合Siamese网络和NestedUNet[55]来提取高分辨率的高级特征。通道注意力应用于解码器每个级别的特征。还采用深度监督来增强中间特征的辨别能力。我们使用具有默认超参数的公共代码来实现上述 CD 网络。  
    我们使用具有默认超参数的公共代码来实现上述 CD 网络。标签。我报告了 LEVIR-CD、WHU-CD 和 DSIFN-CD 测试集的总体比较结果。定量结果表明，我们基于 BIT 的模型在这些数据集中始终优于其他方法，并且具有显着优势。例如，我们的 BIT 的 F1 分数在三个数据集上分别超过最近的 STANet 2/1.6/4.7 点。请注意，我们的 CNN 主干网只是纯 ResNet，我们没有应用 [2] 中的 FPN 或 [9,10,14,22] 中的 UNet 等复杂的结构，这些结构通过融合低层网络，对于像素级预测任务非常强大。具有高空间精度和高级语义特征的级别特征。我们可以得出结论，即使使用简单的主干，我们基于 BIT 的模型也可以实现卓越的性能。这可能归因于我们的 BIT 能够在全局高度抽象的时空范围内对上下文进行建模，并利用上下文来增强像素空间中的特征表示。三个数据集上的方法的可视化比较如图5所示。为了更好地观察，使用不同的颜色来表示TP（白色）、TN（黑色）、FP（红色）、FN（绿色）。我们可以观察到基于 BIT 的模型比其他模型取得了更好的结果。首先，我们基于 BIT 的模型可以更好地避免由于对象的外观与兴趣变化的外观相似而导致的误报（例如，图 5（a）、（e）、（g）、（i））。例如，如图 5（a）所示，大多数比较方法错误地将游泳池区域分类为建筑物变化（视图为红色），而基于通过全局上下文建模增强的判别特征，STANet 和我们的 BIT 可以减少此类错误检测。在图5（c）中，传统方法将道路误认为是建筑物变化，因为道路与建筑物具有相似的颜色行为，并且这些方法由于其有限的接收场而无法排除这些伪变化。其次，我们的BIT还可以很好地处理由季节差异或土地覆盖要素外观变化引起的无关变化（例如图5（b）、（f）和（l））。图 5（f）中建筑物非语义变化的示例说明了我们的 BIT 的有效性，它学习时空域内的有效上下文，以更好地表达真实的语义变化并排除不相关的变化。最后，我们的 BIT 可以针对大范围的变化生成相对完整的预测结果（例如，图 5 (c)、(h) 和 (j)）。例如，在图5（j）中，由于接收场有限，某些比较方法无法完全检测到图像2中的大型建筑区域（显示为绿色），而我们基于BIT的模型呈现出更完整的结果。

### C 模型效率和有效性
    为了公平地比较模型效率，我们在配备 Intel Xeon Silver 4214 CPU 和 NVIDIA Tesla V100 GPU 的计算服务器上测试了所有方法。标签。 II 报告不同方法在 LEVIR-CD、WHU-CD 和 DSIFN-CD 测试集上的参数数量 (Params.)、每秒浮点运算次数 (FLOPs) 和 F1/IoU 分数。  
    首先，我们通过比较卷积对应物来验证我们提出的 BIT 的效率。标签。 II表明，建立在Base S3/Base S4基础上，添加BIT的模型(BIT S3/BIT S4)比具有更多卷积层的模型(Base S4/Base S5)更有效和高效。例如，BIT S4 在三个测试集上的 F1 分数比 Base S5 好 1.7/2.4/10.8 分，同时模型参数数量减少 3 倍，计算成本降低 3 倍。此外，我们可以观察到，与 Base S4 相比，添加更多卷积层仅带来微不足道的改进（即三个测试集上 F1score 的 0.16/0.75/0.18 分），而 BIT 的改进要多得多（即 4∼ 60倍）比CNN的多。  
    其次，我们与四种基于注意力的方法（DTCDSCN、STANet、IFNet 和 SNUNet）进行比较。如表所示。 II，我们的 BIT S4 在 F1/IoU 分数方面优于四个同行，并且计算复杂度和模型参数都非常小，并且具有显着的优势。有趣的是，即使主干网更轻（大约小 10 倍），我们基于 BIT 的模型 (BIT S3) 仍然优于大多数数据集上的四种比较方法。比较结果进一步证明了我们基于 BIT 的模型的有效性和效率。  
    训练可视化。图 6 说明了每个训练时期的训练/验证集的平均 F1 分数。我们可以观察到，虽然 Base 和 BIT 模型在训练精度方面表现相似，但在稳定性和有效性方面，BIT 在验证精度方面优于 Base。这表明BIT的训练更加稳定和高效，并且我们基于BIT的模型具有更强的泛化能力。这可能是因为它能够学习紧凑的上下文丰富的概念，这些概念有效地代表了兴趣的变化。

### D 消融研究
    情境建模。我们对 Transformer Encoder (TE) 进行消融，以验证其在上下文建模中的有效性，其中多头自注意力是 TE 中用于建模上下文的核心组件。从选项卡。 III，当从 BIT 中删除 TE 时，我们可以观察到 LEVIR-CD、WHUCD 和 DSIFN-CD 数据集上的 F1 分数持续显着下降。这表明TE中的self-attention对于建模至关重要基于令牌的时空关系。此外，我们用非局部 [56] 自注意力层替换 BIT，该层能够对基于像素的时空内的关系进行建模。比较结果见表 1。 III 显示我们的 BIT 在三个测试集上的表现明显优于 Nonlocal。可能是因为我们的 BIT 在基于 token 的空间中学习上下文，该空间更紧凑且具有更高的信息密度比 Non-local 更容易，从而有利于关系的有效提取。  
    标记器上的消融。我们通过将分词器从 BIT 中删除来对分词器进行消融。可以认为生成的模型使用了密集标记，这些标记是 CNN 主干提取的特征序列。如表所示。 III，基于 BIT 的模型（w.o. tokenizer）的 F1 分数显着下降。它表明分词器模块在我们基于变压器的框架中至关重要。我们可以看到该模型（不带分词器）仅比 Base S4 稍好一些。这可能是因为密集的特征包含太多的冗余信息，使得基于变压器的模型的训练成为一项艰巨的任务。相反，我们提出的标记器在空间上汇集密集特征来聚合语义信息，从而获得紧凑的概念标记。  
    变压器解码器上的烧蚀。为了验证 Transformer Decoder (TD) 的有效性，我们将其替换为一个简单的模块，以融合来自 TE 的标记 Tinew 和来自 CNN 主干的原始特征 Xi。在 simple 模块中，我们将 Tinew 中每个 token（包含 L 个 token）的空间维度扩展为 RHW 的形状。 L 个扩展标记和 Xi 相加以产生更新的特征，然后将其馈送到预测头。标签。 III 表明在三个测试集上没有 TD 的 BIT 模式 11 的性能持续下降。这可能是因为交叉注意力（TD 的核心部分）提供了一种优雅的方式，通过建模它们的关系来增强原始特征与上下文丰富的标记。此外，BIT（不包括 TE 和 TD）比正常的 BIT 模型要差得多。  
    位置嵌入的效果。 Transformer 架构是排列不变的，而 CD 任务需要空间和时间位置信息。为此，我们将学习到的位置嵌入（PE）添加到馈送到变压器的特征序列中。我们在 TE 和 TD 中对 PE 进行消融。我们设置不包含PE的BIT模型作为基线。如表所示。 IV，当将 PE 添加到馈入 TE 的代币中时，我们的 BIT 模型在三个测试集上实现了 F1 分数的一致改进。它表明双时态标记集中的位置信息对于 TE 中的上下文建模至关重要。与基线相比，将 PE 添加到馈入 TD 的查询时，BIT 模型的 F1 分数没有显着改进。位置信息对于 TD 的查询可能是不必要的，因为 TD 的键（即标记）是高度抽象的并且不包含空间结构。因此，我们在BIT模型中只在TE中添加PE，而在TD中不添加PE。

### E 参数分析
    令牌长度。我们的标记器在空间上将图像的密集特征汇集到一个紧凑的标记集中。我们的直觉是，双时态图像中兴趣的变化可以通过一些视觉概念（即语义标记）来描述。令牌集合L的长度是一个重要的超参数。我们测试不同的 L ∈ {2, 4, 8, 16, 32} 来分析其分别在 LEVIR-CD、WHUCD 和 DSIFN-CD 数据集上对模型性能的影响。标签。 V 显示当将 token 长度从 32 减少到 4 时，模型的 F1 分数有了显着改善。这表明紧凑的 token 集足以表示兴趣变化的语义概念，冗余 token 可能会影响模型性能。我们还可以观察到，当 L 从 4 进一步减小到 2 时，F1 分数略有下降。这是因为当 L 太短时，模型可能会丢失一些与变化概念相关的有用信息。因此，我们将L设置为4。  
    变压器的深度。变压器层数是一个重要的超参数。我们测试了 BIT 模型的不同配置，其中包含不同数量的 TE 和 TD 变压器层。标签。 VI 显示，当增加 Transformer 编码器的深度时，三个数据集上的 BIT 的 F1/IoU 分数没有显着改善。这表明单层 TE 可以很好地学习双时态 token 之间的关系。标签。 VI 还表明模型性能与解码器深度大致正相关。这可能是因为在 Transformer 解码器的每一层之后，通过考虑上下文丰富的标记来细化图像特征。当解码器深度为8时获得最佳结果。虽然进一步增加解码器深度可能会有性能增益，但为了效率和精度之间的权衡，我们将编码器深度设置为1，解码器深度设置为8。  

### F Token 可视化
    我们假设我们的分词器可以提取揭示兴趣变化的高级语义概念。为了更好地理解语义标记，我们将标记器从双时态特征图中提取的注意力图 Ai ∈ RHW ×L 可视化。标记集合Ti中的每个标记Ti l 对应于一个注意力图Ai l ∈ RHW 。图 7 显示了来自 LEVIR-CD、WHU-CD 和 DSIFN-CD 数据集的一些双时图像的标记可视化结果。我们为每个输入图像显示从 Ti 中选择的两个标记的注意力图。红色表示较高的关注值，蓝色表示较低的值。从图7中我们可以看到，提取的标记可以关注属于兴趣变化的语义概念的区域。不同的标记可能涉及不同语义的对象。例如，由于 LEVIR-CD 和 WHU-CD 数据集仅描述建筑物变化，因此这些数据集中的学习标记主要关注属于建筑物的像素。而因为 DSIFN-CD 数据集包含各种变化，这些标记可以突出不同的语义区域，例如建筑物、农田和水体。有趣的是，如图 7 (c) 和 (f) 所示，我们的分词器还可以突出显示建筑物周围的像素（例如阴影），即使在训练我们的模型时没有提供对这些区域的明确监督。这并不奇怪，因为建筑物周围的环境是物体识别的关键线索。这表明我们的模型可以隐式学习一些额外的概念来促进变化识别。

### G 网络可视化
    为了更好地理解我们的模型，我们提供了一个示例来可视化 BIT 模型不同阶段的激活图。给定双时图像（图8（a）），连体FCN生成高级特征图Xi（图8（b））。然后，标记器使用学习到的注意力图 Ai 将特征图在空间上池化为几个标记向量（图 8（c））。然后，由 Transformer 编码器生成的上下文丰富的标记通过 Transformer 解码器投影回像素空间，从而产生细化的特征图 Xinew（图 8（d））。我们展示了来自原始特征 Xi 和精炼特征 Xinew 的四个相应的代表性特征图。从图8（b）和（d）中，我们可以观察到我们的模型可以提取与每个时间图像的兴趣变化相关的高级特征，例如建筑物及其边缘的概念。为了更好地说明BIT模块的效果，精炼后的特征与原始特征之间的差异图像如图8（e）所示。这表明我们的BIT可以进一步突出与变化类别相关的语义概念区域。最后，预测头计算Xinew和Xi之间的特征差异图像（图8（f）），并生成变化概率图P（图8（g））。

## 五、讨论
    我们提供了一种高效且有效的方法来执行高分辨率遥感图像的变化检测。整个时空中同一类别像素的高反射率变化给模型识别感兴趣的对象以及区分真实变化和无关变化带来了困难。时空上下文建模对于增强特征辨别力至关重要。我们提出的 BIT 模块可以有效地对基于 token 的时空中的上下文信息进行建模，并使用上下文丰富的 token 来增强原始特征。与 Base 模型相比，我们的 BIT-base 模型可以生成更准确的预测，误报更少，召回率更高（见图 5 和表 I）。此外，BIT还可以提高模型训练的效率和稳定性（见图6）。这是因为我们的BIT将图像表达为少量的视觉词（token向量），这样的高密度信息可以提高训练效率。我们的 BIT 也可以被视为一种有效的基于注意力的方式，以增加模型的接收范围，从而有利于变化识别的特征表示能力。
