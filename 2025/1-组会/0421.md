# 模型分析与改进

## 1. UNet 模型
### 精度
- **本地训练精度**：约 **50%**
- **上传后精度**：约 **50%**

> 说明：UNet 模型的精度较低，仅为 50% 左右，因此我们主要聚焦在改进 SiamCRNN 模型上。

---

## 2. Siam CRNN 模型分析
![image](https://github.com/user-attachments/assets/96025896-7874-4f89-bab4-f8ffff3b9514)

SiamCRNN 模型用于图像的变化检测（Change Detection, CD），包括两个主要部分：**DSCNN** 和 **MRNN**。

### 2.1 DSCNN（深度Siamese卷积神经网络）
```
self.encoder_1 = torchvision.models.resnet18()
self.encoder_1.load_state_dict(torch.load(local_weights_path))
self.encoder_2 = torchvision.models.resnet18()
self.encoder_2.load_state_dict(torch.load(local_weights_path))
```
#### 作用
DSCNN 负责从图像中提取空间-光谱特征，采用 **ResNet18** 作为卷积网络（Encoder）。该网络结构对于同质图像使用 Siamese 网络架构，对于异质图像则采用伪Siamese结构进行处理。

#### 同质图像处理
对于同质图像，`self.encoder_1` 和 `self.encoder_2` 是完全共享权重的，即这两个网络具有相同的结构，输出的特征也相同，符合 Siamese 网络的设计。

#### 异质图像处理
对于异质图像（例如，来自不同传感器或不同时间段的图像），`self.encoder_1` 和 `self.encoder_2` 网络结构虽然相同，但它们处理的是不同来源的图像数据。这种设计本质上是伪Siamese网络，通过不同的输入数据提取特征，使得模型能够处理来自不同源的图像数据，适应异质图像变化检测任务。

### 2.2 MRNN（多层递归神经网络）
```
self.convlstm_4 = ConvLSTM(input_dim=512 * expansion, hidden_dim=128, kernel_size=(3, 3), num_layers=1, batch_first=True)
self.convlstm_3 = ConvLSTM(input_dim=256 * expansion, hidden_dim=128, kernel_size=(3, 3), num_layers=1, batch_first=True)
self.convlstm_2 = ConvLSTM(input_dim=128 * expansion, hidden_dim=128, kernel_size=(3, 3), num_layers=1, batch_first=True)
self.convlstm_1 = ConvLSTM(input_dim=64 * expansion, hidden_dim=128, kernel_size=(3, 3), num_layers=1, batch_first=True)
```
#### 作用
MRNN 负责对 DSCNN 提取的空间-光谱特征进行时序建模，使用 ConvLSTM 单元对这些特征进行处理。

### 精度
- **本地训练精度**：约 66%
- **上传后精度**：约 67%

---

## 3. 尝试的修改方法

在 SiamCRNN 模型的基础上，我们尝试了以下三种修改方式来进一步提高模型精度。

### 3.1 移除 ResNet18 的预训练模型
在该修改中，我们尝试移除 ResNet18 的预训练模型，或者尝试使用其他的预训练网络进行初始化，但这一修改导致了模型性能的大幅下降。

- **结果**：精度显著下降，无法达到原始精度。
- **说明**：保留 ResNet18 的预训练模型能够获得较好的效果，因此我们决定继续使用预训练模型。

### 3.2 替换 MRNN 中的 ConvLSTM 为 MBConv
我们尝试将 MRNN 中的 ConvLSTM 替换为 MBConv（Mobile Inverted Bottleneck Convolution），该操作旨在提高模型的计算效率，并有望提升精度。

- **本地测试精度**：68%
- **上传后精度**：66%
- **说明**：虽然在本地测试中，替换为 MBConv 后模型精度有所提升，但上传到服务器后效果有所下降。

### 3.3 在 MRNN 基础上增加 Transformer Block
我们在 MRNN 结构上添加了 Transformer Block，以加强模型对时序特征的建模能力。Transformer 是近年来在自然语言处理和计算机视觉中非常有效的架构，具有较强的全局依赖建模能力。

- **本地测试精度**：69%
- **上传后精度**：67.5%
- **说明**：加入 Transformer Block 后，本地精度有显著提升，上传后效果略有下降，但依然超过原始精度。

---

# 比赛排名与精度

目前比赛中，第一名的精度为 **0.7334**（排名 1），总共参与比赛的队伍有 **83** 支。

我们的排名为 **第 25 名**，精度为 **0.6757**。

